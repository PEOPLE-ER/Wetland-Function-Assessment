{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compile Time Series by Units of Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note Description:**\n",
    "\n",
    "This notebook aggregate pixels in Sentinel-1 image time series by landscape units, which were extracted from segmentation of Sentinel-2 composite. It returns an \"average\" time series for each of landscape units that represent the general temporal pattern of S1 backscatter for a certain year. The temporal resolution of the \"average\" time sereis is determined by the interval of Sentinel-1 images, which is 10 days in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "base_dir = '/geoanalytics_user_shared_data/vtang/PEOPLE-ER_Vietnam/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentinel-1 Data\n",
    "\n",
    "- read all GeoTIFF images from a given folder\n",
    "\n",
    "- recommend to put all Sentinel-1 images for a year in a designated folder\n",
    "\n",
    "- the file name of GeoTIFF should include the order number, such as \"***02***\" in \"*an_giang_2022_10d_**02**.tif*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the .tif files in a given folder\n",
    "fpath_list = glob.glob(base_dir + 'sentinel-1/2022/10d_composition/*.tif')\n",
    "\n",
    "# extract image order number from file name\n",
    "x = [int(item.split('_')[-1].split('.')[0]) for item in fpath_list]\n",
    "\n",
    "# load all the tif files as a list of xarray DataArray\n",
    "da_list = []\n",
    "for fpath in fpath_list:\n",
    "    da = rxr.open_rasterio(fpath)  # load Sentinel-1 image\n",
    "    da = da.sel(band=1)  # select VH band\n",
    "    da_list.append(da)\n",
    "\n",
    "# concatenate the list of xarray DataArray\n",
    "da = xr.concat(da_list, pd.Index(x))\n",
    "\n",
    "# convert unit of Sentinel-1 values from linear to decibel\n",
    "da.values = 10 * np.log10(da.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Polygons of Landscape Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('data/an_giang_segmentation.geojson')\n",
    "gdf = gdf.to_crs(da.rio.crs.to_epsg())\n",
    "gdf = gdf.set_index('PID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Pixels by Units\n",
    "\n",
    "- Select one landscape unit (i.e. polygon) and use it to clip Sentinel-1 image stack.\n",
    "- Calculate median of the pixels within polygon for each layer\n",
    "    - layers are the Senitnel-1 image from different dates\n",
    "- Generate 1D array of median as the time series that represent the temporal profile for the selected landscape unit.\n",
    "- Repreat above steps for all polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = da.shape[0]  # number of images (i.e. time steps)\n",
    "df = pd.DataFrame(index=gdf.index, columns=np.arange(1, n + 1))\n",
    "\n",
    "for pid, row in gdf.iterrows():\n",
    "    \n",
    "    # subset image to improve efficiency\n",
    "    xmin, ymin, xmax, ymax = row.geometry.bounds\n",
    "    da2 = da.sel(x=slice(xmin, xmax), y=slice(ymax, ymin))\n",
    "\n",
    "    mask = geometry_mask(\n",
    "        gpd.GeoSeries([row.geometry]),\n",
    "        out_shape=da2.shape[-2:],  # get dimension of x and y\n",
    "        transform=da2.rio.transform(),\n",
    "    )\n",
    "    mask = ~mask\n",
    "\n",
    "    data = da2.values[:, mask]  # select pixels within polygon mask\n",
    "    df.loc[pid] = np.median(data, axis=-1)  # aggregate by median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/vh_2022.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "80ea545c89f4740f2190761fe3f09035380c8ff11000f9cb62822d0fef0270af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
