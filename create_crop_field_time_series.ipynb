{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Description:\n",
    "\n",
    "- need two inputs: time series of S1 images and landscape polygons\n",
    "\n",
    "- need to determine the best landscape segmentation product\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-bgtqi_if because the default path (/home/users/vtang/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "share_folder = '/geoanalytics_user_shared_data/vtang/PEOPLE-ER_Vietnam/'\n",
    "# share_folder = '/home/jovyan/geoanalytics_user_shared_data/vtang/PEOPLE-ER_Vietnam/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sentinel-1 Data\n",
    "\n",
    "- stack time series images (composited at different scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_year = 2022\n",
    "target_nday = 10\n",
    "\n",
    "fpath_list = glob.glob(\n",
    "    share_folder + 'sentinel-1/{}/{}d_composition/*.tif'.format(target_year, target_nday))\n",
    "\n",
    "da_list = [rxr.open_rasterio(fpath) for fpath in fpath_list]\n",
    "\n",
    "# da_list = [\n",
    "#     da.chunk({'band': -1, 'x': 128, 'y':128})\n",
    "#     for da in da_list\n",
    "# ]\n",
    "\n",
    "x = [int(item.split('_')[-1].split('.')[0]) for item in fpath_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = xr.concat(da_list, pd.Index(x))\n",
    "da.values = 10 * np.log10(da.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Landscape Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_file('../data/study_area/rice_crop_fields.shp')\n",
    "gdf = gpd.read_file('../data/study_area/rice_crop_fields_2.geojson')\n",
    "\n",
    "gdf = gdf.to_crs(da.rio.crs.to_epsg())\n",
    "gdf = gdf.sort_values('Type')\n",
    "\n",
    "gdf = gdf.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {}\n",
    "count_list = []\n",
    "\n",
    "for idx, row in gdf.iterrows():\n",
    "    \n",
    "    xmin, ymin, xmax, ymax = row.geometry.bounds\n",
    "    da2 = da.sel(x=slice(xmin, xmax), y=slice(ymax, ymin))\n",
    "\n",
    "    mask = geometry_mask(\n",
    "        gpd.GeoSeries([row.geometry]),\n",
    "        out_shape=da2.shape[-2:],\n",
    "        transform=da2.rio.transform(),\n",
    "    )\n",
    "    mask = ~mask\n",
    "\n",
    "    data = da2.values[:, :, mask]\n",
    "    data = np.mean(data, axis=2)\n",
    "    data_dict.update({idx: data})\n",
    "\n",
    "    count = np.sum(mask)\n",
    "    count_list.append(count)\n",
    "\n",
    "gdf['# Pixels'] = count_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, mat = [], []\n",
    "for i, val in data_dict.items():\n",
    "    idx.append(i)\n",
    "    mat.append(val[:, 0])   \n",
    "mat = np.vstack(mat)\n",
    "df_vh = pd.DataFrame(mat, index=idx, columns=x)\n",
    "df_vh.columns = pd.MultiIndex.from_product([['VH'], df_vh.columns])\n",
    "\n",
    "idx, mat = [], []\n",
    "for i, val in data_dict.items():\n",
    "    idx.append(i)\n",
    "    mat.append(val[:, 1]) \n",
    "mat = np.vstack(mat)\n",
    "df_vv = pd.DataFrame(mat, index=idx, columns=x)\n",
    "df_vv.columns = pd.MultiIndex.from_product([['VV'], df_vv.columns])\n",
    "\n",
    "df_attr = gdf[['Type', '# Pixels']]\n",
    "df_attr.columns = pd.MultiIndex.from_product([['Attr'], ['Type', '# Pixels']])\n",
    "\n",
    "df = pd.concat([df_attr, df_vv, df_vh], axis=1)\n",
    "df.to_csv('../data/crop_time_series/{}_{}d.csv'.format(target_year, target_nday))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "80ea545c89f4740f2190761fe3f09035380c8ff11000f9cb62822d0fef0270af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
